{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2646115,"sourceType":"datasetVersion","datasetId":1609067}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-04T02:13:16.995108Z","iopub.execute_input":"2024-07-04T02:13:16.996767Z","iopub.status.idle":"2024-07-04T02:13:18.490688Z","shell.execute_reply.started":"2024-07-04T02:13:16.996714Z","shell.execute_reply":"2024-07-04T02:13:18.488677Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/headbraincsv/headbrain.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# In this article, let’s learn how to save and load your machine learning model in Python with scikit-learn in this tutorial.\n\nOnce we create a machine learning model, our job doesn’t end there. We can save the model to use in the future. We can either use the pickle or the joblib library for this purpose. The dump method is used to create the model and the load method is used to load and use the dumped model. Now let’s demonstrate how to do it. The save and load methods of both pickle and joblib have the same parameters.","metadata":{}},{"cell_type":"markdown","source":"syntax of dump() method:\n\npickle.dump(obj, file, protocol=None, *, fix_imports=True, buffer_callback=None)\n\nparameters:\n\nobj: The pickled Python object.\nfile: The pickled object will be written to a file or buffer.\nfix_imports: When supplied, the method dump() will determine if the pickling procedure should be compatible with Python version 2 or not based on the value for the pickle protocol option. True is the default value. Only a name-value pair should be used with this default parameter.\nsyntax of load() method:\n\npickle.load(file, *, fix_imports=True, encoding=’ASCII’, errors=’strict’, buffers=None)\n\nThe load() method Returns the rebuilt object hierarchy indicated therein after reading the pickled representation of an object from the open file object file.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# import packages \nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression \nfrom sklearn import metrics \nimport joblib \nimport pickle","metadata":{"execution":{"iopub.status.busy":"2024-07-04T02:42:07.826156Z","iopub.execute_input":"2024-07-04T02:42:07.826622Z","iopub.status.idle":"2024-07-04T02:42:07.833853Z","shell.execute_reply.started":"2024-07-04T02:42:07.826587Z","shell.execute_reply":"2024-07-04T02:42:07.832284Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# import the dataset \ndataset = pd.read_csv('/kaggle/input/headbraincsv/headbrain.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-04T02:22:05.246883Z","iopub.execute_input":"2024-07-04T02:22:05.247321Z","iopub.status.idle":"2024-07-04T02:22:05.257941Z","shell.execute_reply.started":"2024-07-04T02:22:05.247290Z","shell.execute_reply":"2024-07-04T02:22:05.256378Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-04T02:23:54.848503Z","iopub.execute_input":"2024-07-04T02:23:54.849035Z","iopub.status.idle":"2024-07-04T02:23:54.867100Z","shell.execute_reply.started":"2024-07-04T02:23:54.848993Z","shell.execute_reply":"2024-07-04T02:23:54.865611Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"   Gender  Age Range  Head Size(cm^3)  Brain Weight(grams)\n0       1          1             4512                 1530\n1       1          1             3738                 1297\n2       1          1             4261                 1335\n3       1          1             3777                 1282\n4       1          1             4177                 1590","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Age Range</th>\n      <th>Head Size(cm^3)</th>\n      <th>Brain Weight(grams)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4512</td>\n      <td>1530</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>3738</td>\n      <td>1297</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4261</td>\n      <td>1335</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>3777</td>\n      <td>1282</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>4177</td>\n      <td>1590</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X = dataset.iloc[:, : -1].values \nY = dataset.iloc[:, -1].values","metadata":{"execution":{"iopub.status.busy":"2024-07-04T02:24:12.237813Z","iopub.execute_input":"2024-07-04T02:24:12.238262Z","iopub.status.idle":"2024-07-04T02:24:12.244972Z","shell.execute_reply.started":"2024-07-04T02:24:12.238228Z","shell.execute_reply":"2024-07-04T02:24:12.243568Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# train test split \nX_train, X_test, y_train, y_test = train_test_split( \n    X, Y, test_size=0.2, random_state=0) \n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T02:25:14.630048Z","iopub.execute_input":"2024-07-04T02:25:14.630565Z","iopub.status.idle":"2024-07-04T02:25:14.639762Z","shell.execute_reply.started":"2024-07-04T02:25:14.630527Z","shell.execute_reply":"2024-07-04T02:25:14.638214Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# create a linear regression model \nregressor = LinearRegression() \nregressor.fit(X_train, y_train) ","metadata":{"execution":{"iopub.status.busy":"2024-07-04T02:25:34.353483Z","iopub.execute_input":"2024-07-04T02:25:34.353932Z","iopub.status.idle":"2024-07-04T02:25:34.390503Z","shell.execute_reply.started":"2024-07-04T02:25:34.353896Z","shell.execute_reply":"2024-07-04T02:25:34.389473Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"LinearRegression()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Example: Saving and loading models using joblib\nThe SciPy ecosystem includes Joblib, which offers tools for pipelining Python jobs. It offers tools for effectively saving and loading Python objects that employ NumPy data structures. This can be helpful for machine learning algorithms that need to store the complete dataset or have a lot of parameters. let’s look at a simple example where we save and load a linear regression model. The same steps are repeated while using the joblib library.","metadata":{}},{"cell_type":"code","source":"# save the model \nfilename = 'linear_model_2.sav'\njoblib.dump(regressor, open(filename, 'wb')) \n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T02:26:06.883365Z","iopub.execute_input":"2024-07-04T02:26:06.883814Z","iopub.status.idle":"2024-07-04T02:26:06.893889Z","shell.execute_reply.started":"2024-07-04T02:26:06.883781Z","shell.execute_reply":"2024-07-04T02:26:06.892190Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"The .sav extension is commonly used for saved models, but you can use any extension you prefer.\n\nregressor: This is the trained machine learning model that you want to save.\nopen(filename, 'wb'): This opens a file with the specified filename in write-binary mode ('wb'). This mode is used because models are saved as binary files.\njoblib.dump(): This function serializes (saves) the regressor object to the file opened in the previous step.\n\nIn summary, the code saves the trained model (regressor) to a file named linear_model_2.sav using the joblib library. This allows you to store the model on disk and load it later without having to retrain it.","metadata":{}},{"cell_type":"code","source":"# load the model \nload_model = joblib.load(open(filename, 'rb')) \n  \ny_pred = load_model.predict(X_test) \nprint('root mean squared error : ', np.sqrt( \n    metrics.mean_squared_error(y_test, y_pred))) ","metadata":{"execution":{"iopub.status.busy":"2024-07-04T02:32:33.259162Z","iopub.execute_input":"2024-07-04T02:32:33.259657Z","iopub.status.idle":"2024-07-04T02:32:33.270646Z","shell.execute_reply.started":"2024-07-04T02:32:33.259622Z","shell.execute_reply":"2024-07-04T02:32:33.268894Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"root mean squared error :  71.23878018173228\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Example: Saving and loading models using pickle\nPython’s default method for serializing objects is a pickle. Your machine learning algorithms can be serialized/encoded using the pickling process, and the serialized format can then be saved to a file. When you want to deserialize/decode your model and utilize it to produce new predictions, you can load this file later. The training of a linear regression model is shown in the example that follows. In the below example we fit the data with train data and the dump() method is used to create a  model. The dump method takes in the machine learning model and a file is given. The test data is used to find predictions after loading the model using the load() method. root mean square error metric is used to evaluate the predictions of the model.","metadata":{}},{"cell_type":"code","source":"# save the model \nfilename = 'linear_model.sav'\npickle.dump(regressor, open(filename, 'wb')) \n  \n# load the model \nload_model = pickle.load(open(filename, 'rb')) \n  \ny_pred = load_model.predict(X_test) \nprint('root mean squared error : ', np.sqrt( \n    metrics.mean_squared_error(y_test, y_pred)))","metadata":{"execution":{"iopub.status.busy":"2024-07-04T02:42:17.976505Z","iopub.execute_input":"2024-07-04T02:42:17.976936Z","iopub.status.idle":"2024-07-04T02:42:17.988616Z","shell.execute_reply.started":"2024-07-04T02:42:17.976903Z","shell.execute_reply":"2024-07-04T02:42:17.986806Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"root mean squared error :  71.23878018173228\n","output_type":"stream"}]}]}